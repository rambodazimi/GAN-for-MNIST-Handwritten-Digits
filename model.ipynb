{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST"
      ],
      "metadata": {
        "id": "Dot4ETtFEZHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the generator block consisting of a Linear layer followed by a batch normalization and ReLU activation function\n",
        "def generator_block(input_dim, output_dim):\n",
        "  block = nn.Sequential(\n",
        "    nn.Linear(input_dim, output_dim),\n",
        "    nn.BatchNorm1d(output_dim),\n",
        "    nn.ReLU(inplace=True)\n",
        "  )\n",
        "  return block"
      ],
      "metadata": {
        "id": "H-oUELF5NxFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the generator model consisting of 4 generator blocks followed by the last Linear layer with Sigmoid activation function\n",
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        generator_block(input_dim, hidden_dim),\n",
        "        generator_block(hidden_dim, hidden_dim * 2),\n",
        "        generator_block(hidden_dim * 2, hidden_dim * 4),\n",
        "        generator_block(hidden_dim * 4, hidden_dim * 8),\n",
        "        nn.Linear(hidden_dim * 8, output_dim),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "    return self.gen(noise)"
      ],
      "metadata": {
        "id": "4D3bxOqVOF7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating num_samples noise vectors of size z_dim\n",
        "def get_noise(num_samples, z_dim, device='cpu'):\n",
        "  return torch.randn((num_samples, z_dim)).to(device)"
      ],
      "metadata": {
        "id": "eAdmgRw3Oz59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the discriminator block consisting of a Linear layer followed by  LeakyReLU activation function\n",
        "def discriminator_block(input_dim, output_dim):\n",
        "  block = nn.Sequential(\n",
        "      nn.Linear(input_dim, output_dim),\n",
        "      nn.LeakyReLU(0.2, inplace=True)\n",
        "  )\n",
        "  return block"
      ],
      "metadata": {
        "id": "MkEzAooRRlAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the discriminator model consisting of 3 discriminator blocks followed by the last Linear layer\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, hidden_dim):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.disc = nn.Sequential(\n",
        "        discriminator_block(input_dim, hidden_dim * 4),\n",
        "        discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
        "        discriminator_block(hidden_dim * 2, hidden_dim),\n",
        "        nn.Linear(hidden_dim, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "    return self.disc(image)\n",
        "\n",
        "  def get_disc(self):\n",
        "    return self.disc"
      ],
      "metadata": {
        "id": "qtS9LmzGSi2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training parameters\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "n_epochs = 10\n",
        "z_dim = 64\n",
        "hidden_dim = 128\n",
        "lr = 0.00001\n",
        "batch_size = 128\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Loading the MNIST dataset\n",
        "dataloader = DataLoader(MNIST(\".\", download=True, transform=transforms.ToTensor()), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "gen = Generator(z_dim, 784, hidden_dim).to(device) # 784 = 28 x 28\n",
        "gen_opt = optim.Adam(gen.parameters(), lr=lr)\n",
        "\n",
        "disc = Discriminator(784, hidden_dim).to(device)\n",
        "disc_opt = optim.Adam(disc.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "ODB93AKDTL7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the loss of the3 discriminator model given 2 generator and discriminator models, the BCE loss function,\n",
        "# a batch of real examples, the number of images the generator should produce, noise dimension, and device\n",
        "def calculate_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
        "  noise = get_noise(num_samples=num_images, z_dim=z_dim, device=device) # generate noise vectors\n",
        "  gan_fake_output = gen(noise) # produce outputs from the generator\n",
        "\n",
        "  disc_fake_output = disc(gan_fake_output.detach()) # discriminator predictions from the generator's outputs\n",
        "  disc_fake_loss = criterion(disc_fake_output, torch.zeros_like(disc_fake_output)) # calculating loss of discriminator (fake = 0)\n",
        "\n",
        "  disc_real_output = disc(real) # discriminator predictions from the real examples\n",
        "  disc_real_loss = criterion(disc_real_output, torch.ones_like(disc_real_output)) # calculating loss of discriminator (real = 1)\n",
        "\n",
        "  disc_loss = (disc_fake_loss + disc_real_loss) / 2 # average of the 2 losses\n",
        "  return disc_loss"
      ],
      "metadata": {
        "id": "qIpdDK1GWQ5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
        "  noise = get_noise(num_samples=num_images, z_dim=z_dim, device=device) # generate noise vectors\n",
        "  gan_fake_output = gen(noise) # produce outputs from the generator\n",
        "\n",
        "  disc_fake_output = disc(gan_fake_output) # discriminator predictions from the generator's outputs\n",
        "  gen_loss = criterion(disc_fake_output, torch.ones_like(disc_fake_output)) # calculating loss of generator\n",
        "  return gen_loss"
      ],
      "metadata": {
        "id": "-GaFbXp5aanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN Training\n",
        "for epoch in range(n_epochs):\n",
        "  for real, _ in dataloader:\n",
        "    cur_batch_size = len(real)\n",
        "    real = real.view(cur_batch_size, -1).to(device)\n",
        "\n",
        "    disc_opt.zero_grad()\n",
        "    disc_loss = calculate_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
        "    disc_loss.backward(retain_graph=True)\n",
        "    disc_opt.step()\n",
        "\n",
        "    gen_opt.zero_grad()\n",
        "    gen_loss = calculate_gen_loss(gen, disc, criterion, batch_size, z_dim, device)\n",
        "    gen_loss.backward(retain_graph=True)\n",
        "    gen_opt.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "AT41aDvDu35p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}